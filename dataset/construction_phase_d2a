#!/bin/bash

script=$(readlink -f "$0")
export script_dir=$(dirname "$script")
export script_name=$(basename "$script")

export output_dir=$(realpath "$1")
slicing_info_file="$2"
export bitcode_dir=$(realpath "$3")
samples_to_proccess="${4:-1000000000}"
start_from_sample="${5:-1}"
export tmp_dir_general="/tmp/construction_phase_d2a"
joern_script="${tmp_dir_general}/joern_script_d2a"
extracted_samples_file="${tmp_dir_general}/extracted_samples.csv"
tmp_csv_file="${tmp_dir_general}/tmp.csv"

# get the real number of processed samples
all_project_samples_cnt=$(cat ${slicing_info_file} | wc -l)

# colors
export OK='\033[0;92m'
export WARNING='\033[0;93m'
export ERROR='\033[0;31m'
export ENDC='\033[0m'

# function which process a single line in slicing_info_file (single sample)
create_cpgbin() {
    rc=$1
    bug_id=$2
		entry_function=$3
		file=$4
		fun=$5
		line=$6
		variable=$7

		# for storing intermediate files
		tmp_dir="/tmp/construction_phase_d2a_${$}" # unique dir name (using PID)
		bc_sliced="${tmp_dir}/sliced.bc"
		cpg_bin="${tmp_dir_general}/cpg/${bug_id}.cpg.bin.zip"
		bc_combined="${bitcode_dir}/${bug_id}.bc"

		if [ ! -e "${bc_combined}" ]; then
			# samples without bitcode are skipped (they coun as unsuccessfull)
			printf "${WARNING}WARNING${ENDC}: ${script_name}: sample '${bug_id}' doesn't have bitcode!\n"
			exit 0
		fi

		# create tmp dir
		mkdir -p ${tmp_dir}

		# slice the combined LLVM bitcode according to extracted slicing criteria
		# variables already contain required '&' sign
		timeout 3s llvm-slicer --entry=${entry_function} --sc="${file}#${fun}#${line}#${variable}" -o=${bc_sliced} ${bc_combined} > /dev/null 2> ${tmp_dir}/llvm_slicer_stderr.txt

		# check if llvm-slicer timed-out, there are 2 reason for that:
		# 	1) llvm-slicer got stuck
		#		2) llvm-slicer takes too long - the graph will be too large (we dont want it)
		if [ $? -eq 124 ]; then
			printf "${WARNING}WARNING${ENDC}: ${script_name}: skipping bug '${bug_id}' because llvm-slicer timed out for slicing criteria '--entry=${entry_function} --sc=\"${file}#${fun}#${line}#${variable}\"'!\n"
			rm -rf ${tmp_dir}
			exit 0
		fi

		# check if llvm-slicer succeeded
		if grep "No reachable slicing criteria:" ${tmp_dir}/llvm_slicer_stderr.txt > /dev/null
		then
			# llvm-slicer coudn't match extracted slicing criteria to bitcode
			printf "${WARNING}WARNING${ENDC}: ${script_name}: skipping bug '${bug_id}' because llvm-slicer couldn't match the extracted slicing criteria '--entry=${entry_function} --sc=\"${file}#${fun}#${line}#${variable}\"'!\n"
			rm -rf ${tmp_dir}
			exit 0
		fi

		# generate CPG
		llvm2cpg ${bc_sliced} --output=${cpg_bin} > ${tmp_dir}/llvm2cpg_stdout.txt

		# check if llvm2cpg succeeded
		if grep "No bitcode files found." ${tmp_dir}/llvm2cpg_stdout.txt > /dev/null
		then
			# llvm-slicer coudn't match extracted slicing criteria to bitcode (this is not copy-paste error)
			printf "${WARNING}WARNING${ENDC}: ${script_name}: skipping bug ${bug_id} because llvm2cpg failed to generate CPG!\n"
			rm -rf ${tmp_dir}
      rm -rf ${cpg_bin} # if there was an error remove the result (just to be sure)
			exit 0
		fi

    # remove tmp_dir
    rm -rf ${tmp_dir}
}

# function which process a single line in slicing_info_file (single sample)
cpgbin_to_csv() {
    bug_id=$1
    joern_cpg_bin="${tmp_dir_general}/workspace/${bug_id}.cpg.bin.zip/cpg.bin"

    # check if joern succeeded
    # joern stores copy of imported CPG as workspace/${bug_id}.cpg.bin.zip/cpg.bin
    if [ ! -f "${joern_cpg_bin}" ]; then
      # joern failed to import CPG generated by llvm2cpg e.g. the CPG file is missing
      # but when it is there, the cpg.bin is still created (although it may be faulty)
      printf "${WARNING}WARNING${ENDC}: ${script_name}: skipping bug ${bug_id} because Joern failed to create internal representation of given CPG!\n"
      exit 0
    fi

    # export Joern's CPG to CSV
    joern-export --repr all --format neo4jcsv -o "${output_dir}/${bug_id}" ${joern_cpg_bin} > /dev/null 2>&1

    # check if joern-export succeeded
    if [ $? -ne 0 ]
    then
      # joern-export failed probably due to the faulty ${joern_cpg_bin} which
      # was caused by joern's importing which failed half-way
      printf "${WARNING}WARNING${ENDC}: ${script_name}: skipping bug ${bug_id} because joern-export failed to create Neo4j CSV (Joern probably failed to import CPG)!\n"
      exit 0
    fi

    # success
    printf "${OK}SUCCESS${ENDC}: ${script_name}: CPG for bug ${bug_id} was successfully constructed!\n"
  }

# export functions so they are visible in newly started subshells in parallel command
export -f create_cpgbin
export -f cpgbin_to_csv

# recreate tmp dir and cpg dir
rm -rf ${tmp_dir_general} && mkdir -p ${tmp_dir_general}/cpg

# extract only required samples to separate file
head -n ${samples_to_proccess} ${slicing_info_file} | tail -n +${start_from_sample} > ${extracted_samples_file}

# filter out samples with already existing CPGs
while IFS=, read -r rc bug_id rest; do
  # skip the sample if its dir already exists
  if [ -d "${output_dir}/${bug_id}" ]; then
    continue
  fi
  echo "${rc},${bug_id},${rest}"
done < ${extracted_samples_file} > ${tmp_csv_file}

# save it back to the original file
mv ${tmp_csv_file} ${extracted_samples_file}

# we need to switch to tmp, because of joern
cd ${tmp_dir_general}

# split the ${extracted_samples_file} into smaller files of 100 lines each
mkdir ${tmp_dir_general}/split_files/
split -l 100 ${extracted_samples_file} ${tmp_dir_general}/split_files/split_file_

# iterate over each of the smaller files
for file in ${tmp_dir_general}/split_files/split_file_*; do
  if [ ! -e "${file}" ] || [ ! -s "${file}" ]; then
    continue
  fi

  # for each bug report (slicing criteria record)
  cat ${file} | parallel --colsep ',' create_cpgbin {1} {2} {3} {4} {5} {6} {7}

  # filter out samples without cpg.bin.zip
  while IFS=, read -r rc bug_id rest; do
    # skip the sample if the cpg.bin.zip is missing
    if [ ! -f "${tmp_dir_general}/cpg/${bug_id}.cpg.bin.zip" ]; then
      continue
    fi
    echo "${rc},${bug_id},${rest}"
  done < ${file} > ${tmp_csv_file}

  # save it back to the original file
  mv ${tmp_csv_file} ${file}

  # generate joern_script
  while IFS=, read -r rc bug_id rest; do
    echo "importCpg(\"${tmp_dir_general}/cpg/${bug_id}.cpg.bin.zip\")"
  done < ${file} > ${joern_script}
  echo "save" >> ${joern_script}

  # joern transforms generated CPG to CSV in Neo4j format
  # joern creates it's workspace in current dir --> tmp dir general
  joern --script ${joern_script} > /dev/null 2>&1

  # prepare output dir
  mkdir -p ${output_dir} 2> /dev/null

  # run joern-export in parallel
  cat ${file} | parallel --colsep ',' cpgbin_to_csv {2}

  # remove workspace, cpg dir and logs from llvm2cpg - it be wont needed in future and we save some space, since we are creating new CPGs on disk
  rm -rf "${tmp_dir_general}/workspace"
  rm -rf "${tmp_dir_general}/cpg" && mkdir ${tmp_dir_general}/cpg
  rm -rf "/tmp/llvm2cpg-*"
done

if [ "${samples_to_proccess}" -lt "${all_project_samples_cnt}" ]; then
    samples_to_proccess=${samples_to_proccess}
else
    samples_to_proccess=${all_project_samples_cnt}
fi

# get number of successfull/unsuccessfull samples
success_samples_cnt=$(ls ${output_dir} | wc -l)
failed_samples_cnt=$((${samples_to_proccess} - ${success_samples_cnt}))

# if there are more already created graphs than ${samples_to_proccess}
if [ "${success_samples_cnt}" -gt "${samples_to_proccess}" ]; then
    printf "${WARNING}WARNING${ENDC}: ${script_name}: can't determine the number successfull/unsuccessfull samples, because there are more graphs in output dir than the number of graphs to proccess!\n"
    exit 0
fi

# print stats
printf "${WARNING}WARNING${ENDC}: ${script_name}: ${failed_samples_cnt} samples failed to create graph!\n"
printf "${OK}SUCCESS${ENDC}: ${script_name}: ${success_samples_cnt} graphs were successfully created!\n"
