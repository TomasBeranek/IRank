import argparse
import subprocess
import os
import gzip
import pickle
import json
import sys
import shutil
from tqdm import tqdm


# colors
OK='\033[0;92m'
WARNING='\033[0;93m'
ERROR='\033[0;31m'
ENDC='\033[0m'


# HTTPD vars
HTTPD_TRACKED_FILES = ['include/ap_config_auto.h.in',
                       'include/ap_config_layout.h.in',
                       'modules/ssl/ssl_policies.h.in',
                       'buildconf']

# LIBTIFF vars
LIBTIFF_TRACKED_FILES = ['config/config.h.in',
                         'port/libport_config.h.in',
                         'libtiff/tiffvers.h.in',
                         'libtiff/tiffconf.h.in',
                         'libtiff/tif_config.h.in']

# Number of samples for which compilation command failed/succeded
failed_samples = 0
success_samples = 0


def init_parser():
    parser = argparse.ArgumentParser(description='Extracts CPG graph for each sample in D2A dataset and a local copy of given project.')

    parser.add_argument('-r', '--repository', metavar='DIR', required=True, type=str, help='local copy (git clone) of given repository')
    parser.add_argument('-f', '--file', metavar='FILE', required=True, type=str, help='.pickle.gz file with D2A samples')
    parser.add_argument('-s', '--slicing-info', metavar='FILE', required=True, type=str, help='.csv file with slicing information generated by slicing_criteria_extraction.py')
    parser.add_argument('-c', '--commit', metavar='FILE', type=str, help='hash of a commit to start with')
    parser.add_argument('--project', choices=['httpd', 'nginx', 'libtiff'], required=True, type=str, help="project name")
    # parser.add_argument('--include', required=True, type=str, help="path to 'include/' dir for specified project")

    return parser


# Latest hash is first
def get_git_commit_hashes(repository_path):
    command = ['git', 'log', '--all', '--format=%H']
    output = subprocess.check_output(command, cwd=args.repository).decode().strip()
    commit_hashes = output.split('\n')

    return commit_hashes


def get_d2a_hashes(file):
    hashes = dict()

    with gzip.open(file, mode = 'rb') as f:
        while True:
            try:
                sample = pickle.load(f)
            except EOFError:
                break

            # We need to take the 'before' version of each commit
            commit_hash = sample['versions']['before']

            if commit_hash not in hashes:
                # First sample with this hash
                hashes[commit_hash] = dict()

            # Associate current sample with its hash
            hashes[commit_hash][sample['id']] = {'label': sample['label'],
                                                 'compiler_args': sample['compiler_args'] }

    return hashes


# Returns all .bc files in current dir
def find_bitcode_files():
    matches = set()
    for root, _, files in os.walk('.'):
        for file in files:
            if file.endswith('.bc'):
                matches.add(os.path.join(root, file))
    return matches


def find_first_sys_idx(compiler_args):
    idx = -1

    for i, arg in enumerate(compiler_args):
        if '<$sys$>' in arg:
            idx = i
            break

    return idx


def run_compile_commands(compiler_args_dict):
    global failed_samples

    # For each file we generate a single .bc file
    for file, compiler_args in compiler_args_dict.items():
        # DEBUG info:
        print(f'\t{file}')

        # Set current repo path to compiler args
        compiler_args = compiler_args.replace('<$repo$>', os.path.abspath(os.getcwd()))

        # Split args to list
        compiler_args = compiler_args.split(' ')

        # Set library header files path
        if args.project == 'httpd':
            # Find index of first '-I<$sys$>...' arg
            idx = find_first_sys_idx(compiler_args)

            # Check there are any includes of external libraries
            if idx != -1:
                # Remove -I args which include external libraries
                compiler_args = [arg for arg in compiler_args if '<$sys$>' not in arg]

                # Add paths to external libraries instead of their first original occurence in args
                compiler_args = compiler_args[:idx] + ['-Isrclib/apr/include', '-Isrclib/apr-util/include'] + compiler_args[idx:]
        elif args.project == 'nginx':
            # Add paths to headers since in some D2A samples they seem to be missing
            if "-Isrc/core" not in compiler_args:
                compiler_args.append("-Isrc/core")
            if "-Iobjs" not in compiler_args:
                compiler_args.append("-Iobjs")
            if "-Isrc/os/unix" not in compiler_args:
                compiler_args.append("-Isrc/os/unix")
            if "-Isrc/event" not in compiler_args:
                compiler_args.append("-Isrc/event")

        # Add args to generate bitcode
        compile_command = ['clang', '-emit-llvm', '-g', '-grecord-command-line', '-fno-inline-functions', '-fno-builtin'] + compiler_args + ['-c', file]

        # Run the compilation command
        completed_process = subprocess.run(compile_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)

        # Check for failure
        if completed_process.returncode != 0:
            print(" ".join(compile_command))
            print(completed_process.stdout.decode('utf-8'))
            print(completed_process.stderr.decode('utf-8'))
            print(f"{ERROR}ERROR{ENDC}: construction_phase_d2a.py: source files of bug '{id}' failed to compile!", file=sys.stderr)


def files_updated(tracked_files, hash, prev_hash):
    if prev_hash is None:
        # We are at the first commit -> we need to create the headers for the first time
        return True

    # Just for testing
    # git diff --quiet 9fa142563c3bcddafcb892d59c458c87ec278a16 e86620ff6bb77998fde00f7033d283f23184b6fc -- include/ap_config_auto.h include/ap_config_layout.h modules/slotmem/mod_slotmem_shm.c

    # Check if any of tracked files changed between these two commits
    completed_process = subprocess.run(['git', 'diff', '--quiet', hash, prev_hash, '--'] + tracked_files)

    return completed_process.returncode != 0


if __name__ == '__main__':
    parser = init_parser()
    args = parser.parse_args()

    # Get chronological list of hashes
    hashes = get_git_commit_hashes(args.repository)

    # Get set of hashes present in D2A dataset
    d2a_hashes = get_d2a_hashes(args.file)

    # Remove hashes (commits) in which we are not interested in (not in D2A)
    hashes = [hash for hash in hashes if hash in d2a_hashes.keys()]

    # Navigate to given repository
    os.chdir(args.repository)

    # Latest commit is now last
    hashes = list(reversed(hashes))

    # Start from defined commit
    if args.commit:
        while hashes and hashes[0] != args.commit:
            hashes.pop(0)

    # Check if we have dependencies for specified project
    if args.project == 'httpd':
        if not os.path.exists('../httpd-dependencies/srclib/apr') or not os.path.exists('../httpd-dependencies/srclib/apr-util'):
            print(f"{ERROR}ERROR{ENDC}: construction_phase_d2a.py: external libraries '../httpd-dependencies/srclib/apr' or '../httpd-dependencies/srclib/apr-util' for httpd project are missing!", file=sys.stderr)
            exit(1)

    # Iterate over hashes and switch repository to given commits
    prev_hash = None
    for hash in tqdm(hashes):
        # We want to restore all files to 'HASH' commit and delete any leftovers from previous compilation
        subprocess.run(['git', 'reset', '--hard', hash])
        subprocess.run(['git', 'clean', '-dfx'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

        if args.project == 'httpd':
            # We need copy back external libs and generated .h files (unless the template changed)
            # NOTE: Even if the template didn't change, the actual .h could change, because it takes
            #       values from various sources. But it would be too time consuming to find all the
            #       sources. We also can't generate the .h for each commit as that would be too
            #       computionally expensive. Therefore we have to do an APPROXIMATION, where we generate
            #       (update) all the .h files only when:
            #         1) any of the templates changed
            #         2) buildconf changed

            # Copy back external libs
            shutil.copytree('../httpd-dependencies/srclib/apr', 'srclib/apr')
            shutil.copytree('../httpd-dependencies/srclib/apr-util', 'srclib/apr-util')
            # This is from the newest version of HTTPD
            try:
                # We need to copy this, because sometimes it is missing
                shutil.copytree('../httpd-dependencies/srclib/pcre', 'srclib/pcre')
            except FileExistsError:
                # The pcre/ was present in the repo
                pass

            # In commit ff7722bc9a 'util_pcre.c' requires PCRE Version 6.7 or later,
            # but supplied version in this repo is lower (5.0) and compilation fails.
            # So we force the compilation to use the manually installed PCRE.
            # shutil.rmtree('srclib/pcre')

            # Header files from .h.in templates
            if files_updated(HTTPD_TRACKED_FILES, hash, prev_hash):
                # Generate new header files
                completed_process = subprocess.run(['./buildconf'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
                if completed_process.returncode != 0:
                    print(completed_process.stdout.decode('utf-8'))
                    print(completed_process.stderr.decode('utf-8'))
                    print(f"{WARNING}WARNING{ENDC}: construction_phase_d2a.py: command './buildconf' failed!", file=sys.stderr)

                completed_process = subprocess.run(['./configure'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
                if completed_process.returncode != 0:
                    print(completed_process.stdout.decode('utf-8'))
                    print(completed_process.stderr.decode('utf-8'))
                    print(f"{WARNING}WARNING{ENDC}: construction_phase_d2a.py: command './configure' failed!", file=sys.stderr)

                # Save generated files
                os.makedirs('/tmp/d2a_pipeline', exist_ok=True)
                shutil.copy('include/ap_config_auto.h', '/tmp/d2a_pipeline/')
                shutil.copy('include/ap_config_layout.h', '/tmp/d2a_pipeline/')
                try:
                    shutil.copy('modules/ssl/ssl_policies.h', '/tmp/d2a_pipeline/')
                except FileNotFoundError:
                    # The ssl_policies.h.in file is added in later versions of httpd
                    # TODO: We can dynamically get a list of .h.in files present and copy files based on this
                    #       find . -type f -name "*.h.in"
                    pass
            else:
                # Copy back old generated headers
                shutil.copy('/tmp/d2a_pipeline/ap_config_auto.h', 'include/')
                shutil.copy('/tmp/d2a_pipeline/ap_config_layout.h', 'include/')
                try:
                    shutil.copy('/tmp/d2a_pipeline/ssl_policies.h', 'modules/ssl/')
                except FileNotFoundError:
                    # The ssl_policies.h.in file is added in later versions of httpd
                    pass

            # Header files from .c templates
            # Some info: https://httpd.apache.org/docs/2.4/platform/netware.html
            if files_updated(['server/gen_test_char.c', 'srclib/pcre/dftables.c'], hash, prev_hash):
                # The 'test_char.h' is generated as stdout of 'server/gen_test_char.c'
                subprocess.run(['gcc', '-Isrclib/apr/include', '-Isrclib/apr-util/include', 'server/gen_test_char.c', '-o', 'gen_test_char'])
                with open('include/test_char.h', 'w') as f:
                    subprocess.run(['./gen_test_char'], stdout=f)
                shutil.copy('include/test_char.h', '/tmp/d2a_pipeline/')

                # The 'chartables.c' is generated using 'srclib/pcre/dftables.c'
                subprocess.run(['gcc', 'srclib/pcre/dftables.c', '-o', 'dftables'])
                subprocess.run(['./dftables', 'include/chartables.c'])
                shutil.copy('include/chartables.c', '/tmp/d2a_pipeline/')
            else:
                shutil.copy('/tmp/d2a_pipeline/test_char.h', 'include/')
                shutil.copy('/tmp/d2a_pipeline/chartables.c', 'include/')
        elif args.project == 'nginx':
            # Generate header files (in NGINX's case its pretty fast)
            completed_process = subprocess.run(['./auto/configure'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            if completed_process.returncode != 0:
                print(completed_process.stdout.decode('utf-8'))
                print(completed_process.stderr.decode('utf-8'))
                print(f"{WARNING}WARNING{ENDC}: construction_phase_d2a.py: command './auto/configure' failed!", file=sys.stderr)
        elif args.project == 'libtiff':
            # Generate header files (in LIBTIFF's case its pretty fast)
            completed_process = subprocess.run(['./autogen.sh'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            if completed_process.returncode != 0:
                print(completed_process.stdout.decode('utf-8'))
                print(completed_process.stderr.decode('utf-8'))
                print(f"{WARNING}WARNING{ENDC}: construction_phase_d2a.py: command './autogen.sh' failed!", file=sys.stderr)
            completed_process = subprocess.run(['./configure'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            if completed_process.returncode != 0:
                print(completed_process.stdout.decode('utf-8'))
                print(completed_process.stderr.decode('utf-8'))
                print(f"{WARNING}WARNING{ENDC}: construction_phase_d2a.py: command './configure' failed!", file=sys.stderr)

        # Iterate over samples in each commit
        # (multiple samples could have been found in a single commit)
        for id, val in d2a_hashes[hash].items():
            # OPTIMIZE: if the files are the same as in the last sample, no need to run the compilation (it happens very often)

            if args.project == 'httpd':
                # We don't want to delete srclib/ (external libs) and generated .h files (they are up2date now)
                subprocess.run(['git', 'clean', '-dfx', '--exclude=srclib/', '--exclude=include/'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                # This needs to copied back to server/, because it was deleted by previous command
                shutil.copy('include/test_char.h', 'server/')
            elif args.project == 'nginx':
                # We don't want to delete objs/ (generated .h files)
                subprocess.run(['git', 'clean', '-dfx', '--exclude=objs/'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            elif args.project == 'libtiff':
                # We don't want to delete generated .h files
                subprocess.run(['git', 'clean', '-dfx', '--exclude=config/', '--exclude=port/', '--exclude=libtiff/'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)


            # Check for existing .bc files (we dont want those)
            old_bc_files = find_bitcode_files()

            # Create .bc files
            run_compile_commands(val['compiler_args'])

            new_bc_files = find_bitcode_files()
            added_bc_files = new_bc_files - old_bc_files

            # Check if we have .bc file for each compilation command
            if len(added_bc_files) == len(val['compiler_args']):
                print(f"{OK}SUCCESS{ENDC}: construction_phase_d2a.py: source files of bug '{id}' were successfully compiled!", file=sys.stderr)
                success_samples += 1
            else:
                # Some .bc files may have been generated, but since some are missing we CAN'T use this sample
                print(f"{ERROR}ERROR{ENDC}: construction_phase_d2a.py: compilation of bug '{id}' failed to generate all .bc files!", file=sys.stderr)
                failed_samples += 1

        prev_hash = hash

    # Print final statistics
    if failed_samples:
        print(f"{WARNING}WARNING{ENDC}: construction_phase_d2a.py: {failed_samples} samples out of {failed_samples + success_samples} failed to compile!", file=sys.stderr)
    else:
        print(f"{OK}SUCCESS{ENDC}: construction_phase_d2a.py: all {success_samples} samples successfully compiled!", file=sys.stderr)

    # git checkout branchname       - to lastest commit in given branch
    # git checkout hash             - to given commit
    # git clean -df                 - to remove untracked files (.bc files)
    # git reset --hard HEAD         - hard reset of repo - restore tracked files and remove untracked

    # latest 4b0266174814e6cf60a275321121dbaab084ee64
    # latest in d2a a5895eb502747f396d3901a948834cd87d5fb0c3
